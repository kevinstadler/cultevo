<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Spike's measure of additive compositionality. — sm.compositionality • cultevo</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


<!-- Google analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96498670-1', 'auto');
  ga('send', 'pageview');

</script>

  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">cultevo</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">Overview</a>
</li>
<li>
  <a href="../reference/index.html">Function reference</a>
</li>
<li>
  <a href="../articles/page.test.html">Page test tutorial</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/kevinstadler/cultevo">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Spike's measure of additive compositionality.</h1>
    </div>

    
    <p>Implementation of the Spike-Montague information-theoretic measure of
additive compositionality (Spike 2016), which finds the most predictive
association between substrings and categorical meaning features. Additive
means that it does not take the ordering of elements into account, i.e.
<code>GREEN DOG = GREEN + DOG = DOG + GREEN</code>.</p>
    

    <pre><span class='fu'>sm.compositionality</span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='kw'>groups</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>strict</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)

<span class='fu'>sm.segmentation</span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='kw'>strict</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>a list or vector of character sequences specifying the signals to
be analysed. Alternatively, <code>x</code> can also be a formula of the format
<code>s ~ m1 + m2 + ...</code>, where <code>s</code> and <code>m*</code> specify the column
names of the signals and meaning features found in the data frame that's
passed as the second argument.</p></td>
    </tr>
    <tr>
      <th>y</th>
      <td><p>a matrix or data frame with as many rows as there are signals,
indicating the presence/value of the different meaning dimensions along
columns (see section Meaning data format). If <code>x</code> is a formula, the
second argument can contain any number of columns, only the ones specified
in the formula will be considered.</p></td>
    </tr>
    <tr>
      <th>groups</th>
      <td><p>a list or vector with as many items as strings, used to split
<code>strings</code> and <code>meanings</code> into data sets for which
compositionality measures are computed separately.</p></td>
    </tr>
    <tr>
      <th>strict</th>
      <td><p>logical: if <code>TRUE</code>, perform additional filtering of
candidate segments. In particular, it removes combinations of segments
(across meanings) which overlap in at least one of the strings where they
co-occur. For convenience, it also removes segments which are shorter
substrings of longer candidates (for the same meaning feature).</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p><code>sm.compositionality</code> calculates the mean predictability of all
  meaning features and their most predictably co-occurring strings. Returns
  a vector of three elements: <code>N</code> is the number of signal-meaning
  pairings on which the computation was based, <code>comp</code> the mean mutual
  predictability, and <code>M</code> the number of distinct meaning features over
  which this average was computed. (When <code>groups</code> is not <code>NULL</code>,
  returns a matrix with the same elements along columns, with one row for
  every group.)</p>
<p><code>sm.segmentation</code> provides detailed information about the most
  predictably co-occurring segments for every meaning feature. It returns
  a data frame with one row for every meaning feature, in descending order
  of their predictability from (and to) their corresponding string
  segments. The data frame has the following columns:</p><dl class='dl-horizontal'>
    <dt><code>N</code></dt><dd><p>The number of signal-meaning pairings in which this
      meaning feature was attested.</p></dd>
    <dt><code>mp</code></dt><dd><p>The highest mutual predictability between this
      meaning feature and one (or more) segments that was found.</p></dd>
    <dt><code>p</code></dt><dd><p>Significance levels of the mutual predictability for the
      given segment(s). The calculation depends on the frequency of the
      meaning feature as well as the overall frequency of the segment
      across all signals and indicates the (null) probability of the given
      co-occurrence count of the two according to the hypergeometric
      distribution. If multiple segments are tied for their mutual
      predictability, the candidate list is filtered to include only those
      with the highest significance levels (i.e. the lowest p values).</p></dd>
    <dt><code>ties</code></dt><dd><p>The number of substrings found in <code>strings</code>
      which have this same level of mutual predictability with the meaning
      feature.</p></dd>
    <dt><code>segments</code></dt><dd><p>For <code>strict = FALSE</code>: a list containing the
      <code>ties</code> substrings in descending order of their length (the
      ordering is for convenience only and not inherently meaningful). When
      <code>strict = TRUE</code>, the lists of segments for each meaning feature
      are all of the same length, with a meaningful relationship of the
      order of segments across the different rows: every set of segments
      which are found in the same position for each of the different
      meaning features constitute a valid segmentation where the segments
      occurrences in the actual signals do not overlap.</p></dd>
  </dl>

    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>The measure really captures the degree to which a synonymy-free signalling
system exists at the level of semantic <em>features</em>, rather than looking
for complex meanings per se. The resulting segmentations may therefore
overlap, which means <em>holistic</em> signalling systems can currently still
get relative high compositionality scores. A modification to account for
this is under development.</p>
<p>The segmentation algorithm scans through all sub-strings found in
<code>strings</code> to find the most bijective mapping onto all the meaning
features present in <code>meanings</code>, i.e. the pairings of sub-strings and
meaning features that are <em>most predictive of each other</em>.
Mathematically, for every meaning feature \(f\in M\), it tries to find
the sub-string \(s_{ij}\) from the set of strings \(S\) that maximises
$$comp(f,S) = \max_{s_{ij}\in S}\ P(f|s_{ij}) \cdot P(s_{ij}|f)$$.</p>
<p>Based on these mappings onto individual meaning features,
<code>sm.compositionality</code> then computes the average mutual predictability
over all meaning features \(M\),
$$comp(M,S) = \frac{1}{|M|} \sum_{f\in M} comp(f,S),$$
as a measure of the overall compositionality of the signalling system.</p>
    
    <h2 class="hasAnchor" id="meaning-data-format"><a class="anchor" href="#meaning-data-format"></a>Meaning data format</h2>

    
    <p>The <code>meanings</code> can be a matrix or data frame in one of two formats. If
it is a matrix of logicals (TRUE/FALSE values), then the columns are
assumed to refer to meaning <em>features</em>, with individual cells
indicating whether the meaning feature is present or absent in the message
indicated by that row (see <code><a href='binaryfeaturematrix.html'>binaryfeaturematrix</a></code> for an
explanation).
If <code>meanings</code> is a data frame or matrix of any other type, it is
assumed that the columns specify different meaning dimensions, with the
cell values showing the levels with which the different dimensions can be
realised. This dimension-based representation is automatically converted to
a feature-based one using <code><a href='binaryfeaturematrix.html'>binaryfeaturematrix</a></code>. As a
consequence, whatever the actual types of the columns in the meaning
matrix, <em>they will be treated as categorical factors</em> in order to
represent them as atomic meaning features.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Spike, M. (2016). Minimal requirements for the cultural
  evolution of language. PhD thesis, The University of Edinburgh.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <p><code><a href='binaryfeaturematrix.html'>binaryfeaturematrix</a></code>, <code><a href='ssm.compositionality.html'>ssm.compositionality</a></code></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># perfect communication system</span>
<span class='fu'>sm.compositionality</span>(<span class='fu'>c</span>(<span class='st'>"a"</span>, <span class='st'>"b"</span>, <span class='st'>"ab"</span>),
  <span class='fu'>cbind</span>(<span class='kw'>a</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>TRUE</span>, <span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>), <span class='kw'>b</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>, <span class='fl'>TRUE</span>)))</div><div class='output co'>#&gt;   N comp M
#&gt; 1 3    1 2</div><div class='input'><span class='fu'>sm.segmentation</span>(<span class='fu'>c</span>(<span class='st'>"a"</span>, <span class='st'>"b"</span>, <span class='st'>"ab"</span>),
  <span class='fu'>cbind</span>(<span class='kw'>a</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>TRUE</span>, <span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>), <span class='kw'>b</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>, <span class='fl'>TRUE</span>)))</div><div class='output co'>#&gt;   N mp     p ties segments
#&gt; a 2  1 0.333    1        a
#&gt; b 2  1 0.333    1        b
#&gt; 
#&gt; Mean feature-wise mutual predictability, weighted by feature frequency: 1 </div><div class='input'>
<span class='co'># not quite perfect communication system</span>
<span class='fu'>sm.compositionality</span>(<span class='fu'>c</span>(<span class='st'>"as"</span>, <span class='st'>"bas"</span>, <span class='st'>"basf"</span>),
  <span class='fu'>cbind</span>(<span class='kw'>a</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>TRUE</span>, <span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>), <span class='kw'>b</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>, <span class='fl'>TRUE</span>)))</div><div class='output co'>#&gt;   N      comp M
#&gt; 1 3 0.8333333 2</div><div class='input'><span class='fu'>sm.segmentation</span>(<span class='fu'>c</span>(<span class='st'>"as"</span>, <span class='st'>"bas"</span>, <span class='st'>"basf"</span>),
  <span class='fu'>cbind</span>(<span class='kw'>a</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>TRUE</span>, <span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>), <span class='kw'>b</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>, <span class='fl'>TRUE</span>)))</div><div class='output co'>#&gt;   N    mp     p ties   segments
#&gt; b 2 1.000 0.333    3 bas, ba, b
#&gt; a 2 0.667 1.000    3   as, a, s
#&gt; 
#&gt; Mean feature-wise mutual predictability, weighted by feature frequency: 0.833 </div><div class='input'>
<span class='co'># force candidate segments to be non-overlapping via the 'strict' option</span>
<span class='fu'>sm.segmentation</span>(<span class='fu'>c</span>(<span class='st'>"as"</span>, <span class='st'>"bas"</span>, <span class='st'>"basf"</span>),
  <span class='fu'>cbind</span>(<span class='kw'>a</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>TRUE</span>, <span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>), <span class='kw'>b</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>FALSE</span>, <span class='fl'>TRUE</span>, <span class='fl'>TRUE</span>)), <span class='kw'>strict</span><span class='kw'>=</span><span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; <span class='message'>Applying strict selection, checking 9 segment combinations for overlap</span></div><div class='output co'>#&gt;   N    mp     p ties segments
#&gt; b 2 1.000 0.333    2    s, ba
#&gt; a 2 0.667 1.000    2    as, b
#&gt; 
#&gt; Mean feature-wise mutual predictability, weighted by feature frequency: 0.833 </div><div class='input'>
<span class='co'># the function also accepts meaning-dimension based matrix definitions:</span>
<span class='fu'>print</span>(<span class='no'>twobytwoanimals</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='enumerate.meaningcombinations.html'>enumerate.meaningcombinations</a></span>(<span class='fu'>c</span>(<span class='kw'>animal</span><span class='kw'>=</span><span class='fl'>2</span>, <span class='kw'>colour</span><span class='kw'>=</span><span class='fl'>2</span>)))</div><div class='output co'>#&gt;      colour animal
#&gt; [1,]      1      3
#&gt; [2,]      1      4
#&gt; [3,]      2      3
#&gt; [4,]      2      4</div><div class='input'>
<span class='co'># note how there are many more candidate segments than just the full length</span>
<span class='co'># ones. given limited data, it is expected that shorter substrings will be</span>
<span class='co'># just as predictable as the full segments that contain them.</span>
<span class='fu'>sm.segmentation</span>(<span class='fu'>c</span>(<span class='st'>"greendog"</span>, <span class='st'>"greencat"</span>, <span class='st'>"bluedog"</span>, <span class='st'>"bluecat"</span>), <span class='no'>twobytwoanimals</span>)</div><div class='output co'>#&gt;          N mp     p ties     segments
#&gt; colour=1 2  1 0.167   12 green, g....
#&gt; colour=2 2  1 0.167    9 blue, bl....
#&gt; animal=3 2  1 0.167    5 dog, do,....
#&gt; animal=4 2  1 0.167    6 cat, ca,....
#&gt; 
#&gt; Mean feature-wise mutual predictability, weighted by feature frequency: 1 </div><div class='input'>
<span class='co'># since there is no overlap in the constituent characters of the identified</span>
<span class='co'># 'morphemes', they are all tied in their mutual predictiveness with the</span>
<span class='co'># (shorter) substrings they contain</span>

<span class='co'># to reduce the pool of candidate segments to those which are</span>
<span class='co'># non-overlapping and of maximal length, again use the 'strict=TRUE' option:</span>

<span class='fu'>sm.segmentation</span>(<span class='fu'>c</span>(<span class='st'>"greendog"</span>, <span class='st'>"greencat"</span>, <span class='st'>"bluedog"</span>, <span class='st'>"bluecat"</span>), <span class='no'>twobytwoanimals</span>,
  <span class='kw'>strict</span><span class='kw'>=</span><span class='fl'>TRUE</span>)</div><div class='output co'>#&gt; <span class='message'>Applying strict selection, checking 3240 segment combinations for overlap</span></div><div class='output co'>#&gt;          N mp     p ties segments
#&gt; colour=1 2  1 0.167    1    green
#&gt; colour=2 2  1 0.167    1     blue
#&gt; animal=3 2  1 0.167    1      dog
#&gt; animal=4 2  1 0.167    1      cat
#&gt; 
#&gt; Mean feature-wise mutual predictability, weighted by feature frequency: 1 </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#meaning-data-format">Meaning data format</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Kevin Stadler.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
